{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f7eff7-dfa0-45c2-981a-9d54c3294345",
   "metadata": {},
   "source": [
    "# @ Jani Kuhno\n",
    "# Model from https://keras.io/examples/vision/deeplabv3_plus/\n",
    "# by Soumik Rakshit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e563af-50ae-457f-bb88-c636d870e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "import keras_cv\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For data preprocessing\n",
    "from tensorflow import image as tf_image\n",
    "from tensorflow import data as tf_data\n",
    "from tensorflow import io as tf_io\n",
    "from tensorflow.keras.utils import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551cf79-8f5f-4e2b-bd66-9ff06ceebe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGE_SIZE: indicating one side length of a square image, when needing a tuple of WxH, use (IMAGE_SIZE, IMAGE_SIZE)\n",
    "#BATCH_SIZE: smaller models might fit memory with larger batch size, experiment with batch size and optimizer learning rate\n",
    "#NUM_CLASSES: how many classes are annotated by replicator, take into account background and unclassified which come automatic\n",
    "#input_dir: directory for training data, same as output_dir in replicator\n",
    "#NUM_TRAIN_IMAGES: how many samples to train on\n",
    "#NUM_VAL_IMAGES: how many samples to validate on\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 512\n",
    "BATCH_SIZE = 4\n",
    "NUM_CLASSES = 4\n",
    "input_dir = \"your_dataset_output_path\"\n",
    "NUM_TRAIN_IMAGES = 5000\n",
    "NUM_VAL_IMAGES = 50\n",
    "EPOCHS = 10\n",
    "\n",
    "AUTOTUNE = tf_data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27779a17-525e-4342-bd53-3077581cbd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading, built-in keras function will not work for image segmentation targets\n",
    "\n",
    "# sorted list of sample file paths, as many as NUM_TRAIN_IMAGES, from the first file\n",
    "input_img_paths = sorted(\n",
    " [os.path.join(input_dir, fname)\n",
    " for fname in os.listdir(input_dir)\n",
    " if fname.startswith(\"rgb\")])[:NUM_TRAIN_IMAGES]\n",
    "\n",
    "# sorted list of target file paths, as many as NUM_TRAIN_IMAGES\n",
    "target_paths = sorted(\n",
    " [os.path.join(input_dir, fname)\n",
    " for fname in os.listdir(input_dir)\n",
    " if fname.endswith(\".png\") and not fname.startswith(\"rgb\")])[:NUM_TRAIN_IMAGES]\n",
    "\n",
    "\"\"\"\n",
    "# sorted list of validation sample file paths, as many as NUM_VAL_IMAGES, from the first file not included in training images\n",
    "val_img_paths = sorted(\n",
    " [os.path.join(input_dir, fname)\n",
    " for fname in os.listdir(input_dir)\n",
    " if fname.startswith(\"rgb\")])[NUM_TRAIN_IMAGES : NUM_VAL_IMAGES + NUM_TRAIN_IMAGES]\n",
    "\n",
    "# sorted list of validation target file paths, as many as NUM_VAL_IMAGES\n",
    "val_target_paths = sorted(\n",
    " [os.path.join(input_dir, fname)\n",
    " for fname in os.listdir(input_dir)\n",
    " if fname.endswith(\".png\") and not fname.startswith(\"rgb\")])[NUM_TRAIN_IMAGES : NUM_VAL_IMAGES + NUM_TRAIN_IMAGES]\n",
    "\"\"\"\n",
    "\n",
    "# support function for loading images\n",
    "# bool mask not in use, bool rotate for rotating iphone pictures for inference\n",
    "# read the file, decode it from string tensor to a uint8 tensor, resize it to match IMAGE_SIZE\n",
    "def read_image(image_path, mask=False, rotate=False):\n",
    "    image = tf_io.read_file(image_path)\n",
    "    image = tf_image.decode_png(image, channels=3)\n",
    "    image.set_shape([None, None, 3])\n",
    "    image = tf_image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "    if rotate:\n",
    "        image = tf_image.rot90(image=image, k=3)\n",
    "    return image\n",
    "\n",
    "\n",
    "# takes a path of a target, returns the target\n",
    "def path_to_target(path):\n",
    "    img = img_to_array(load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE), color_mode=\"grayscale\"))\n",
    "    img = img.astype(\"uint8\")\n",
    "    return img\n",
    "\n",
    "\n",
    "# prevents the targets from going to read_image\n",
    "def load_data(image_list, mask_list):\n",
    "    image = read_image(image_list)\n",
    "    #mask = read_image(mask_list, mask=True)\n",
    "    return image, mask_list\n",
    "\n",
    "\n",
    "# in case CutMix augmentation is needed, keras_cv_CutMix layer inputs are dicts with keys \"images\" and \"labels\"\n",
    "def to_dict(image, label):\n",
    "     return {\"images\": image, \"labels\": label}\n",
    "\n",
    "\n",
    "# apply keras_cv Cutout augmentation layer to data\n",
    "random_cutout = keras_cv.layers.RandomCutout(0.1, 0.1)\n",
    "def apply_augment(samples, targets):\n",
    "    samples = random_cutout(samples)\n",
    "    return samples, targets\n",
    "\n",
    "\n",
    "# loop the targets to an np array, create a tf_data dataset, map the dataset to load images, shuffle, batch the dataset and apply augment\n",
    "def data_generator(image_list, mask_list):\n",
    "    targets = np.zeros((len(mask_list),) + (IMAGE_SIZE, IMAGE_SIZE) + (1,), dtype=\"uint8\")\n",
    "    for i in range(len(mask_list)): \n",
    "        targets[i] = path_to_target(mask_list[i])\n",
    "    dataset = tf_data.Dataset.from_tensor_slices((image_list, targets))\n",
    "    dataset = dataset.map(load_data, num_parallel_calls=AUTOTUNE)\n",
    "   # dataset = dataset.map(to_dict, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.shuffle(400)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    dataset = dataset.map(apply_augment, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_dataset = data_generator(input_img_paths, target_paths)\n",
    "#val_dataset = data_generator(val_img_paths, val_target_paths)\n",
    "\n",
    "\n",
    "print(\"Train Dataset:\", train_dataset)\n",
    "#print(\"Val Dataset:\", val_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77423381-6413-4d39-929c-f0188723970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return ops.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04295b8-54a3-411e-b3de-d4eb22696c43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    preprocessed = keras.applications.resnet50.preprocess_input(model_input)\n",
    "    resnet50 = keras.applications.ResNet50(\n",
    "        weights=\"imagenet\", include_top=False, input_tensor=preprocessed\n",
    "    )\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "    return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "\n",
    "model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737509f9-34f7-4dc6-b0ae-d99b8afb6b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=loss,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"models/deeplab.keras\", save_best_only=True),\n",
    "    # keras.callbacks.TensorBoard(log_dir=\"tensorboard\", write_images=True,)\n",
    "]\n",
    "\n",
    "# calling model checkpoint callback has error with keras ResNet preprocessing layer, TODO: fix\n",
    "history = model.fit(train_dataset, \n",
    "                    #validation_data=val_dataset, \n",
    "                    epochs=EPOCHS, \n",
    "                    #callbacks=callbacks,\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f17f4-ec88-44cf-a139-b72c228bf64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom colormap in order to colorize our predictions as a segmentation mask\n",
    "#                        R  G  B\n",
    "colormap = np.asarray([[0, 99, 0], # class id 0\n",
    "                       [99, 0, 0], # class id 1\n",
    "                       [0, 0, 99], # class id 2\n",
    "                       [66, 0, 33] # class id 3\n",
    "                       ], \n",
    "                       dtype=np.uint8)\n",
    "\n",
    "\n",
    "def infer(model, image_tensor):\n",
    "    # add a batch axis and convert to a numpy array\n",
    "    predictions = model.predict(np.expand_dims((image_tensor), axis=0))\n",
    "    \n",
    "    # remove 1D axes, in this case the batch axis\n",
    "    predictions = np.squeeze(predictions)\n",
    "\n",
    "    # get the indices with higest value along the softmax prediction axis, results in a class id for each pixel\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# apply our colormap to the pixel ints given by infer function\n",
    "# mask is the prediction matrix, shape of 512, 512\n",
    "def decode_segmentation_masks(mask, colormap, n_classes):\n",
    "    # make a 512x512 matrix for each color value in rgb\n",
    "    r = np.zeros_like(mask).astype(np.uint8)\n",
    "    g = np.zeros_like(mask).astype(np.uint8)\n",
    "    b = np.zeros_like(mask).astype(np.uint8)\n",
    "\n",
    "    # l classes from 0 to NUM_CLASSES, each r,g,b array gets indexed by a shape 512, 512 array of booleans indicating a given class l\n",
    "    # each iteration of the loop updates the values r,g,b matrices for a given class\n",
    "    # for example, when l is 1, idx matrix gets True values for those indices where the prediction matrix has values 1\n",
    "    for l in range(0, n_classes):\n",
    "        idx = mask == l\n",
    "        r[idx] = colormap[l, 0]\n",
    "        g[idx] = colormap[l, 1]\n",
    "        b[idx] = colormap[l, 2]\n",
    "\n",
    "    # stack the r,g,b arrays to get an rgb array of shape 512,512,3 \n",
    "    rgb = np.stack([r, g, b], axis=2)\n",
    "    return rgb\n",
    "\n",
    "\n",
    "# display_list is the real world picture and its corresponding predicted rgb-colorized mask, figsize to configure the size \n",
    "def plot_samples_matplotlib(display_list, figsize=(5, 3)):\n",
    "    # make subplots to display both the image and its mask\n",
    "    # _ for Figure is of no use, axs is a list of the subplots (one row, two columns for each image we are predicting)\n",
    "    _, axs = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)\n",
    "\n",
    "    # separate rgb images and segmentation masks by checking if the last axis is ,3 which is the rgb axis\n",
    "    for i in range(len(display_list)):\n",
    "        if display_list[i].shape[-1] == 3:\n",
    "            axs[i].axis('off')\n",
    "            axs[i].imshow(keras.utils.array_to_img(display_list[i]))\n",
    "        else:\n",
    "            axs[i].axis('off')\n",
    "            axs[i].imshow(display_list[i])\n",
    "    plt.show()\n",
    "\n",
    "# collection function for all the support functions\n",
    "# gets called with a list of pictures to predict, a colormap to colorize the prediction and a trained model to use in inference\n",
    "# remember to adjust rotate boolean when calling read_image\n",
    "def plot_predictions(images_list, colormap, model):\n",
    "    for image_file in images_list:\n",
    "        image_tensor = read_image(image_file, rotate=False)\n",
    "        prediction_mask = infer(image_tensor=image_tensor, model=model)\n",
    "        prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, NUM_CLASSES)\n",
    "        plot_samples_matplotlib(\n",
    "            [image_tensor, prediction_colormap], figsize=(18, 14)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad384b-8c10-42aa-b15b-8bbbcb31c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_paths_list = sorted(\n",
    "    [os.path.join('path_to_test_data, fname)\n",
    "    for fname in os.listdir('path_to_test_data')\n",
    "    if fname.startswith(\"rgb\")])\n",
    "\n",
    "plot_predictions(input_paths_list, colormap, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2011ddd7-8593-4338-976f-fccb2f6c13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_classes(target_arr):\n",
    "    testing = target_arr[:, :, 0] \n",
    "    unique_ids = np.unique(testing)\n",
    "    #labels in hand labelled ground truth\n",
    "    labels = {\"0\": {\"class\":\"background\"}, \n",
    "              \"1\": {\"class\": \"table\"}, \n",
    "              \"2\": {\"class\": \"props\"}}\n",
    "    # matching labels with SD\n",
    "    CUSTOM_LABELS = {\n",
    "                \"background\": 0,\n",
    "                \"props\": 2,\n",
    "                \"table\": 3,\n",
    "        }\n",
    "\n",
    "    corrected_class_ids = np.zeros((testing.shape[0], testing.shape[1]), dtype=np.uint8)\n",
    "    for i, _id in enumerate(unique_ids):\n",
    "        obj_label = [*labels[str(_id)].values()][0].lower()\n",
    "        if obj_label in CUSTOM_LABELS:\n",
    "            corrected_class_ids[testing == _id] = CUSTOM_LABELS[obj_label]\n",
    "\n",
    "    print(\"Corrected label id's: \" + str(np.unique(corrected_class_ids, return_counts=True)))\n",
    "    return corrected_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e115d6-73a9-45cd-9851-0190ced50ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU metric to evaluate the data numerically\n",
    "\n",
    "results_list = []\n",
    "m = keras.metrics.MeanIoU(num_classes=NUM_CLASSES)\n",
    "\n",
    "for i in range(len(input_paths_list)):\n",
    "\n",
    "    metrics_img_path = f'path_to_test_data/rgb_{i}.jpg'\n",
    "    ground_truth_path = f'path_to_test_data/mask_{i}.png'\n",
    "\n",
    "    # remember to rotate if needed\n",
    "    metrics_img = read_image(metrics_img_path, rotate=False)\n",
    "    metrics_pred = infer(model, metrics_img)\n",
    "    ground_truth = path_to_target(ground_truth_path)\n",
    "    ground_truth = correct_classes(ground_truth)\n",
    "\n",
    "    # calculate the mean of IoU values of all classes\n",
    "    m.reset_state()\n",
    "    m.update_state(ground_truth, metrics_pred)\n",
    "    results_list.append(m.result().numpy())\n",
    "    #print(results_list[i])\n",
    "\n",
    "for i in results_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21991440-1a57-40ee-876e-ef5450e3debd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
